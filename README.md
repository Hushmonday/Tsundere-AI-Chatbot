Tsundere AI Chatbot

A local bilingual AI assistant that can both flirt and code.
Built with Qwen2.5 and LoRA fine-tuning â€” supports personalized chat and Python code execution.

Overview

Tsundere AI Chatbot is a locally deployed intelligent chat system that combines
LLM fine-tuning, LoRA parameter-efficient training, and real-time Python code execution.

It allows users to chat naturally in both Chinese and English,
while also generating and running executable Python code â€”
making it a blend of a charming AI companion and a practical coding assistant.

âœ¨ Key Features
Feature	Description
Tsundere Personality Chat	Custom fine-tuned conversational style with a bilingual â€œtsundereâ€ (playfully sassy) tone.
LoRA Fine-Tuning	Train and personalize the model efficiently using lightweight Low-Rank Adaptation.
Model Merging & Loading	Automatically detects and merges LoRA weights for faster, memory-efficient inference.
Python Code Execution	Recognizes and executes code blocks in real-time (e.g., python ... ).
Multi-Turn Context	Maintains full conversation history for coherent and natural dialogue.
Fully Local Deployment	Runs 100% offline â€” no API calls, ensuring privacy and security.
Tech Stack
Category	Tools / Frameworks
Model Framework	Hugging Face Transformers

Fine-Tuning Method	PEFT / LoRA

Data Format	JSON (role-based conversation data)
Base Model	Qwen2.5-1.5B-Instruct

UI Framework	Gradio ChatInterface

Language	Python 3.10+
Environment	Compatible with both CPU and GPU
Project Structure
chatbot/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.json                # Training dataset (custom bilingual dialogue)
â”‚
â”œâ”€â”€ checkpoints_lora/             # Intermediate LoRA checkpoints
â”œâ”€â”€ chat_model_lora/              # Fine-tuned LoRA model
â”œâ”€â”€ chat_model/                   # Base model (Qwen2.5)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                  # Base model training script
â”‚   â”œâ”€â”€ train_lora.py             # LoRA fine-tuning script
â”‚   â”œâ”€â”€ chat_app.py               # Chat interface (conversation + code execution)
â”‚   â””â”€â”€ utils.py                  # Utility functions
â”‚
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # Documentation

Installation
1ï¸âƒ£ Install dependencies
git clone https://github.com/yourusername/tsundere-chatbot.git
cd tsundere-chatbot
pip install -r requirements.txt


ğŸ’¡ On Windows, the script automatically disables bitsandbytes to avoid CUDA DLL issues.

2ï¸âƒ£ Prepare the model

Download and place your models under:

chat_model/           # Qwen2.5-1.5B-Instruct base model
chat_model_lora/      # LoRA fine-tuned model (optional)


If you only have the base model, fine-tune it yourself using:

python src/train_lora.py

3ï¸âƒ£ Launch the chatbot
python src/chat_app.py


Once started, youâ€™ll see something like:

* Running on local URL: http://127.0.0.1:7860


Then open http://127.0.0.1:7860
 in your browser.

ğŸ’¬ Chat Examples
1ï¸âƒ£ Regular Chat
User: ä½ å¥½  
Bot: Hmph! Itâ€™s not like I missed you or anythingâ€¦ hello! ğŸ˜¤

2ï¸âƒ£ Python Code Generation
User: Write a Python function to print the first 10 Fibonacci numbers.
Bot:
```python
def fibonacci(n):
    a, b = 0, 1
    for _ in range(n):
        print(a)
        a, b = b, a + b

fibonacci(10)


ğŸ§  Execution Result:

0  
1  
1  
2  
3  
5  
8  
13  
21  
34

ğŸ”¬ Training Workflow

Prepare personalized dialogue data in data/train.json.

Run LoRA fine-tuning with:

python src/train_lora.py


Save weights under chat_model_lora/.

Launch chat_app.py â€” it will automatically load your fine-tuned model.

ğŸ¯ Highlights

âœ… Lightweight and Efficient â€” Fine-tune with only ~6GB VRAM.
ğŸ’¬ Customizable Personality â€” Swap in new dialogue datasets for new â€œcharacters.â€
ğŸ’» Code + Conversation Hybrid â€” Generates and runs Python code locally.
ğŸ”’ Offline and Private â€” No external API calls or data sharing.
ğŸŒ Bilingual Support â€” Fluent in English and Chinese.

ğŸ§© Example Training Data
[
  {
    "messages": [
      {"role": "user", "content": "Hello"},
      {"role": "assistant", "content": "Hmph, finally remembered me? Fine... hello there!"}
    ]
  },
  {
    "messages": [
      {"role": "user", "content": "Who are you?"},
      {"role": "assistant", "content": "Iâ€™m your adorable AI assistant! But donâ€™t get too attached, okay? ğŸ˜¤"}
    ]
  },
  {
    "messages": [
      {"role": "user", "content": "Write a Python example."},
      {"role": "assistant", "content": "Of course! Hereâ€™s a simple one:\n```python\ndef hello():\n    print('Hello, world!')\nhello()\n```"}
    ]
  }
]

ğŸ§  Future Roadmap

 Add long-term memory for persistent conversations

 Support math and symbolic reasoning

 Integrate RAG for knowledge retrieval

 Build a web interface using React/Vue

 Add speech input and TTS responses